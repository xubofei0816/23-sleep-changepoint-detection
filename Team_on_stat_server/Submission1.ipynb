{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c185d699-433f-45bb-80ae-be3bf72d28b1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Import libraries and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bdfffb-cc2a-44b7-8d5b-ba138f80d6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from IPython.display import Markdown\n",
    "import cmdstanpy\n",
    "import tempfile\n",
    "from trendfilter import trend_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cda2076-5c5a-4170-9b70-c7f31c93b77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 19.3 ms, total: 44.2 ms\n",
      "Wall time: 94.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import polars as pl\n",
    "test_series = (pl.scan_parquet('test_series.parquet')\n",
    "                .with_columns(\n",
    "                    (\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\")),\n",
    "#                         (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.year().alias(\"year\")),\n",
    "#                         (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.month().alias(\"month\")),\n",
    "#                         (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.day().alias(\"day\")),\n",
    "#                         (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.hour().alias(\"hour\")),\n",
    "                    )\n",
    "                )\n",
    "                .collect()\n",
    "                .to_pandas()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76767e69-34e7-47a4-9075-54673692156d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_ns_dtype\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \n",
    "    \"\"\" \n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object and not is_datetime64_ns_dtype(df[col]):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        \n",
    "\n",
    "    df['series_id'] = df['series_id'].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f'Decreased by {decrease:.2f}%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76bd304-b675-4add-99f3-623a7de0f341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.01 MB\n",
      "Memory usage after optimization is: 0.01 MB\n",
      "Decreased by 23.71%\n"
     ]
    }
   ],
   "source": [
    "test_series = reduce_mem_usage(test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2df874c-8378-4a66-a3ed-a29cc4ecba2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series_ids = test_series['series_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6505934-5aac-4c5f-b72c-bdad3fe041f1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5f54ab-df81-4f7b-9bc1-ef0fc317e29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stan_model = \"\"\"\n",
    "data {\n",
    "  int T;\n",
    "  vector[T] y;\n",
    "}\n",
    "parameters {\n",
    "  // real<lower = 0> sigma;\n",
    "  // real<lower = 0> tau;\n",
    "  real<lower = 0, upper = 1> xi1_init; \n",
    "}\n",
    "transformed parameters {\n",
    "  matrix[T, 2] eta;\n",
    "  matrix[T, 2] xi;\n",
    "  vector[T] f;\n",
    "  \n",
    "  // fill in etas\n",
    "  for(t in 1:T) {\n",
    "    if(t==1) {\n",
    "      eta[t,1] = exp(normal_lpdf(y[t]| 0, 20));    \n",
    "      eta[t,2] = exp(normal_lpdf(y[t]| 0, 20));\n",
    "    } else {\n",
    "      eta[t,1] = exp(normal_lpdf(y[t]| 0.9*y[t-1], 20));\n",
    "      eta[t,2] = 0.99 * exp(normal_lpdf(y[t]| y[t-1], .1)) + 0.01 * exp(normal_lpdf(y[t]| 0.9*y[t-1], 20));\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // work out likelihood contributions\n",
    "  \n",
    "  for(t in 1:T) {\n",
    "    // for the first observation\n",
    "    if(t==1) {\n",
    "      f[t] = 0.999*xi1_init*eta[t,1] + // stay in state 1\n",
    "             (1 - 0.999)*xi1_init*eta[t,2] + // transition from 1 to 2\n",
    "             0.999*(1 - xi1_init)*eta[t,2] + // stay in state 2 \n",
    "             (1 - 0.999)*(1 - xi1_init)*eta[t,1]; // transition from 2 to 1\n",
    "      \n",
    "      xi[t,1] = (0.999*xi1_init*eta[t,1] +(1 - 0.999)*(1 - xi1_init)*eta[t,1])/f[t];\n",
    "      xi[t,2] = 1.0 - xi[t,1];\n",
    "    \n",
    "    } else {\n",
    "    // and for the rest\n",
    "      \n",
    "      f[t] = 0.999*xi[t-1,1]*eta[t,1] + // stay in state 1\n",
    "             (1 - 0.999)*xi[t-1,1]*eta[t,2] + // transition from 1 to 2\n",
    "             0.999*xi[t-1,2]*eta[t,2] + // stay in state 2 \n",
    "             (1 - 0.999)*xi[t-1,2]*eta[t,1]; // transition from 2 to 1\n",
    "      \n",
    "      // work out xi\n",
    "      \n",
    "      xi[t,1] = (0.999*xi[t-1,1]*eta[t,1] +(1 - 0.999)*xi[t-1,2]*eta[t,1])/f[t];\n",
    "      \n",
    "      // there are only two states so the probability of the other state is 1 - prob of the first\n",
    "      xi[t,2] = 1.0 - xi[t,1];\n",
    "    }\n",
    "  }\n",
    "  \n",
    "}\n",
    "model {\n",
    "  // priors\n",
    "  // sigma ~ cauchy(0, 10);\n",
    "  // tau ~ cauchy(0, 10);\n",
    "  xi1_init ~ beta(2, 2);  \n",
    "  \n",
    "  target += sum(log(f));\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa79838-f9f9-41c4-93d3-543ae47a41d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.stan') as stan_file:\n",
    "    stan_file.write(stan_model)\n",
    "    stan_file_path = stan_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0ee979-21d4-418d-9fac-6a8bb15ba198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:04:46 - cmdstanpy - INFO - compiling stan file /tmp/tmp5k8kuxih.stan to exe file /tmp/tmp5k8kuxih\n",
      "19:05:07 - cmdstanpy - INFO - compiled model executable: /tmp/tmp5k8kuxih\n"
     ]
    }
   ],
   "source": [
    "model = cmdstanpy.CmdStanModel(stan_file=stan_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e024bf0-a8c6-42be-a484-ffa1ea94e6ba",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15c5639e-7c59-416a-82f5-c9d79056d477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:18:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:18:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:18:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:18:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:18:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:18:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(columns = ['series_id', 'step', 'event', 'score'])\n",
    "\n",
    "for i in range(len(series_ids)):\n",
    "    test_data = test_series[test_series.series_id == series_ids[i]]\n",
    "    length = test_data.shape[0]\n",
    "    data = {\"T\": length, 'y' : np.array(test_data.anglez)}\n",
    "    mle = model.optimize(data=data)\n",
    "    pred = np.round(mle.stan_variable('xi')[:, 0])\n",
    "    pred_new = pred\n",
    "    \n",
    "    x = np.linspace(0, len(pred), len(pred))\n",
    "    alpha = 10\n",
    "    while ((length * 5)/3600/24 + 1 < sum(pred_new[1:] != pred_new[:-1])):\n",
    "        tf = trend_filter(x, pred, l_norm = 1, alpha_1 = alpha + 10)\n",
    "        pred_new = np.round(tf['y_fit'])\n",
    "        \n",
    "    \n",
    "    onsets = sum((pred_new[1:] - pred_new[:-1]) == -1)\n",
    "    if onsets > 0:\n",
    "        output = output.append(test_data.iloc[1:, :].iloc[(pred[1:] - pred[:-1]) == -1, 0:2], ignore_index = True)\n",
    "        output['event'][(len(output.index)-onsets) : ] = 'onset'\n",
    "\n",
    "    wakeups = sum((pred_new[1:] - pred_new[:-1]) == 1)\n",
    "    if wakeups > 0:\n",
    "        output = output.append(test_data.iloc[1:, :].iloc[(pred[1:] - pred[:-1]) == 1, 0:2], ignore_index = True)\n",
    "        output['event'][(len(output.index)-wakeups) : ] = 'wakeup'\n",
    "\n",
    "    output['score'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4723a014-69f9-401f-a39e-863136a55781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.to_csv('submission.csv', index_label = 'row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efb9db-1829-4917-8f0e-6341ef3fffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
